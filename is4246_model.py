# -*- coding: utf-8 -*-
"""IS4246 Model.pynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o1gROBsgQNo9RIcVLTt0sRZYq551BZDc

Environment Setup
"""

# ======================================
# Environment Setup
# ======================================

"""1) Imports & Reproducibility"""

# --- imports & seeds ---
from io import StringIO
import sys
import os, random, json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from pathlib import Path
import argparse

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import shap
from copy import deepcopy

from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,
                             precision_recall_curve, roc_curve, f1_score)

SEED = 42
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

"""2) Data Loading & Preprocessing

    In this section, we load the loan approval dataset and prepare it for model training. The preprocessing steps include encoding categorical variables, mapping the target variable to numeric form, creating a derived feature (has_debt), handling missing values, and splitting the data into training, validation, and test sets. Finally, all numeric features are standardized using StandardScaler to ensure consistent scaling across inputs.

    This is to ensure that the features for the model are on a similar scale, preventing variables with larger numerical ranges (such as income or asset value) from dominating the learning process. Standardizing the data also helps the neural network converge faster and achieve more stable performance during training.

    We are using all the features provided in the dataset, and we also engineered an additional feature called has_debt, which indicates whether an individual has any negative asset values. This derived feature helps the model capture the applicant’s overall financial health by reflecting existing liabilities or debts to make the dataset more realistic. Including this feature provides the model with a clearer view of each applicant’s risk profile, potentially improving its ability to distinguish between approved and rejected loan applications.
"""

# --- data loading & preprocessing ---
def preprocess_data(df, seed=SEED):
    dfp = df.copy()

    # encode categoricals
    categorical_cols = ['education', 'self_employed']
    label_encoders = {}
    for col in categorical_cols:
        le = LabelEncoder()
        dfp[col] = le.fit_transform(dfp[col].astype(str))
        label_encoders[col] = le

    # target mapping
    status_map = {'Approved': 1, 'Rejected': 0}
    dfp['loan_status'] = dfp['loan_status'].map(status_map).astype(int)
    label_encoders['loan_status'] = status_map

    # base features
    base_cols = [
        'no_of_dependents','education','self_employed','income_annum',
        'loan_amount','loan_term','cibil_score','residential_assets_value',
        'commercial_assets_value','luxury_assets_value','bank_asset_value'
    ]

    X = dfp[base_cols].copy()
    y = dfp['loan_status'].copy()

    # derived feature
    asset_cols = ['residential_assets_value','commercial_assets_value',
                  'luxury_assets_value','bank_asset_value']
    X['has_debt'] = (X[asset_cols].lt(0).any(axis=1)).astype(int)

    feature_cols = base_cols + ['has_debt']

    # impute & split (70/15/15 stratified)
    X = X.fillna(X.median(numeric_only=True))
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=0.30, stratify=y, random_state=seed
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=seed
    )

    # scale using train only
    scaler = StandardScaler().fit(X_train)
    X_train = scaler.transform(X_train)
    X_val   = scaler.transform(X_val)
    X_test  = scaler.transform(X_test)

    return (X_train, y_train, X_val, y_val, X_test, y_test,
            scaler, label_encoders, feature_cols)

#Loading Data
def load_dataset():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--csv",
        type=str,
        default=None,
        help="Optional path to CSV; defaults to repo's data/loan_approval_dataset.csv"
    )
    args, _ = parser.parse_known_args()

    # Default: data/loan_approval_dataset.csv relative to this file
    repo_root = Path(__file__).resolve().parent
    default_csv = repo_root / "data" / "loan_approval_dataset.csv"
    csv_path = Path(args.csv) if args.csv else default_csv

    if not csv_path.exists():
        raise FileNotFoundError(
            f"Dataset not found at: {csv_path}\n"
            "Tip: pass a custom file with --csv /path/to/your.csv"
        )
    print(f"Loading dataset from: {csv_path}")
    return pd.read_csv(csv_path)

# Use it:
df = load_dataset()

"""3) TensorDatasets & DataLoaders

    In this section, the preprocessed data is converted into PyTorch tensors and organized into DataLoader objects to streamline model training and evaluation.

    The to_tensor_ds() function transforms the feature (X) and label (y) arrays into a TensorDataset, which is the required input format for PyTorch models.
    
    The make_loaders() function then creates three DataLoader objects each for training, validation, and testing. Training loader uses shuffle=True to randomize the data each epoch for better generalization.
"""

# --- dataloaders ---
def to_tensor_ds(X, y):
    y_arr = y.values.reshape(-1, 1) if hasattr(y, "values") else np.array(y).reshape(-1, 1)
    return TensorDataset(torch.tensor(X, dtype=torch.float32),
                         torch.tensor(y_arr, dtype=torch.float32))

def make_loaders(X_train, y_train, X_val, y_val, X_test, y_test, batch_size=64):
    train_ds = to_tensor_ds(X_train, y_train)
    val_ds   = to_tensor_ds(X_val,   y_val)
    test_ds  = to_tensor_ds(X_test,  y_test)

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)
    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)
    return train_loader, val_loader, test_loader

"""4) Model Architecture

    This section covers the model architecture which is a deep neural network model built using PyTorch’s nn.Module. It consists of five fully connected (linear) layers with decreasing neuron sizes (512 → 256 → 128 → 64 → 32), each followed by batch normalization and ReLU activation to improve learning stability and non-linearity.
    
    To prevent overfitting, dropout layers (with rates 0.4, 0.3, and 0.2) are applied after the first three layers. The final output layer has a single neuron that produces a logit value, which represents the probability of loan approval after applying a sigmoid function during evaluation.
    
    This architecture allows the model to capture complex, non-linear relationships among the financial and demographic features of applicants.

    We selected a deep neural network model because thay are black-box models that can simulate complex decision-making processes similar to those in AI systems.
"""

# --- model ---
class LoanApprovalModel(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.layer1 = nn.Linear(input_size, 512); self.bn1 = nn.BatchNorm1d(512)
        self.layer2 = nn.Linear(512, 256);        self.bn2 = nn.BatchNorm1d(256)
        self.layer3 = nn.Linear(256, 128);        self.bn3 = nn.BatchNorm1d(128)
        self.layer4 = nn.Linear(128,  64);        self.bn4 = nn.BatchNorm1d(64)
        self.layer5 = nn.Linear( 64,  32);        self.bn5 = nn.BatchNorm1d(32)
        self.dropout1 = nn.Dropout(0.4)
        self.dropout2 = nn.Dropout(0.3)
        self.dropout3 = nn.Dropout(0.2)
        self.output = nn.Linear(32, 1)  # logits

    def forward(self, x):
        x = F.relu(self.bn1(self.layer1(x))); x = self.dropout1(x)
        x = F.relu(self.bn2(self.layer2(x))); x = self.dropout2(x)
        x = F.relu(self.bn3(self.layer3(x))); x = self.dropout3(x)
        x = F.relu(self.bn4(self.layer4(x)))
        x = F.relu(self.bn5(self.layer5(x)))
        return self.output(x)  # raw logits

"""5) Loss function, Optimizer, Scheduler

    This section defines the loss function, optimiser and scheduler of the model. The loss function used here is binary cross entropy with logit loss. This loss function combines a sigmoid activation with binary cross-entropy loss. This loss function is more numerically stable than using a Sigmoid followed by a Binary Cross Entropy Loss because it prevent overflow and underflow issues (where numerical values become too large or too small).

    The AdamW optimizer is chosen for its stability and ability to prevent overfitting through weight decay. Furthermore, AdamW optimiser is efficient in graident descent, making it more convenient choice.

    Lastly, we used a learning rate scheduler (ReduceLROnPlateau) that automatically reduces the learning rate when the validation loss stops improving. This helps the model fine-tune its learning during later epochs, prevents oscillations, and promotes smoother convergence toward an optimal solution.
"""

# --- training config helpers ---
def make_training_objects(model, y_train):
    pos = float(y_train.sum())
    neg = float(len(y_train) - y_train.sum())
    pos_weight_value = (neg / max(pos, 1.0)) if pos > 0 else 1.0

    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value], device=DEVICE))
    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)
    return criterion, optimizer, scheduler

"""6) Model Training (with Early Stopping)

    This section defines the training loop that iteratively updates the model’s parameters to minimize loss. The loop trains the model using batches of data from the training set and evaluates its performance on the validation set at each epoch.

    During each iteration, the model performs a forward pass to generate predictions and compute the loss, followed by backward propagation to calculate gradients. The optimizer then updates the model’s weights. Gradient clipping is applied to prevent exploding gradients (overly large gradients that can cause unstable training).
    
    Validation loss and accuracy are tracked throughout to monitor performance. An early stopping mechanism is included to prevent overfitting where the training stops if the validation loss does not improve after a set number of epochs.
"""

# --- training loop ---
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,
                epochs=10, early_stop_patience=20, ckpt_path='best_model.pth'):
    train_losses, val_losses, train_accs, val_accs, lrs = [], [], [], [], []
    best_val = float('inf'); patience = 0

    for epoch in range(epochs):
        # train
        model.train()
        tloss, correct, total = 0.0, 0, 0
        for x, y in train_loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            optimizer.zero_grad()
            logits = model(x)
            loss = criterion(logits, y)
            loss.backward()
            nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            tloss += loss.item()
            preds = (torch.sigmoid(logits) > 0.5).float()
            correct += (preds == y).sum().item()
            total += y.size(0)

        train_loss = tloss / len(train_loader)
        train_acc = 100.0 * correct / total

        # val
        model.eval()
        vloss, vcorrect, vtotal = 0.0, 0, 0
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(DEVICE), y.to(DEVICE)
                logits = model(x)
                vloss += criterion(logits, y).item()
                preds = (torch.sigmoid(logits) > 0.5).float()
                vcorrect += (preds == y).sum().item()
                vtotal += y.size(0)

        val_loss = vloss / len(val_loader)
        val_acc = 100.0 * vcorrect / vtotal

        scheduler.step(val_loss)
        train_losses.append(train_loss); val_losses.append(val_loss)
        train_accs.append(train_acc);    val_accs.append(val_acc)
        lrs.append(optimizer.param_groups[0]['lr'])

        # early stopping
        if val_loss < best_val:
            best_val = val_loss; patience = 0
            torch.save(model.state_dict(), ckpt_path)
        else:
            patience += 1
            if patience >= early_stop_patience:
                break

    model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))
    return train_losses, val_losses, train_accs, val_accs, lrs

"""7) Threshold Tuning (by F1 on Validation)


    This section defines the tune_threshold() function, which determines the optimal classification threshold for the model.
    
    By default, binary classifiers use a threshold of 0.5 to separate the two classes. However, this may not always yield the best results, especially with imbalanced data. The function evaluates multiple threshold values (from 0.05 to 0.95) and computes the F1 score for each. The threshold that gives the highest F1 score (balancing both precision and recall) is selected as the optimal threshold for final model evaluation.
"""

# --- threshold tuning ---
def tune_threshold(model, loader):
    model.eval()
    probs_all, y_all = [], []
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            probs = torch.sigmoid(model(x)).cpu().numpy().ravel()
            probs_all.append(probs); y_all.append(y.cpu().numpy().ravel())
    probs = np.concatenate(probs_all); y_true = np.concatenate(y_all)

    ths = np.linspace(0.05, 0.95, 19)
    f1s = []
    for t in ths:
        f1s.append(f1_score(y_true, (probs >= t).astype(int)))
    best_idx = int(np.argmax(f1s))
    return float(ths[best_idx]), float(f1s[best_idx])

"""8) Model Evaluation

    This section is where we evaluate the model which measure it's performance on the test dataset with the optimal threshold. We computes the common key metrics such as such as loss, accuracy, and AUC (Area Under the ROC Curve) to assess predictive performance. We also generates a classification report summarizing precision, recall, and F1-score. Together, these metrics and visualizations provide a comprehensive understanding of how well the model generalizes to unseen data.

"""

# --- evaluation ---
def evaluate(model, loader, criterion, threshold=0.5, label_names=('Rejected','Approved')):
    model.eval()
    tloss, correct, total = 0.0, 0, 0
    probs_all, y_all = [], []

    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            logits = model(x)
            tloss += criterion(logits, y).item()
            probs = torch.sigmoid(logits).cpu().numpy().ravel()
            probs_all.append(probs); y_all.append(y.cpu().numpy().ravel())
            preds = (probs >= threshold).astype(np.float32)
            correct += (preds == y.cpu().numpy().ravel()).sum()
            total += len(preds)

    loss = tloss / len(loader)
    probs = np.concatenate(probs_all); y_true = np.concatenate(y_all)
    acc = 100.0 * correct / total
    auc = roc_auc_score(y_true, probs)

    preds_bin = (probs >= threshold).astype(int)
    print(f"Loss: {loss:.4f} | Acc: {acc:.2f}% | AUC: {auc:.4f}\n")
    print("Classification Report:")
    print(classification_report(y_true, preds_bin, target_names=list(label_names)))

    cm = confusion_matrix(y_true, preds_bin)
    plt.figure(figsize=(5.5,4.5)); sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
        xticklabels=list(label_names), yticklabels=list(label_names))
    plt.title('Confusion Matrix'); plt.ylabel('True'); plt.xlabel('Predicted'); plt.tight_layout(); plt.show()

    fpr, tpr, _ = roc_curve(y_true, probs)
    plt.figure(figsize=(5.5,4.5)); plt.plot(fpr, tpr, label=f'AUC={auc:.3f}'); plt.plot([0,1],[0,1],'--')
    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve'); plt.legend(); plt.tight_layout(); plt.show()

    prec, rec, _ = precision_recall_curve(y_true, probs)
    plt.figure(figsize=(5.5,4.5)); plt.plot(rec, prec)
    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision–Recall Curve'); plt.tight_layout(); plt.show()

    return acc, auc, probs, y_true

"""9) Permutation Feature Importance

    This section defines the permutation_importance() function, which measures how much each feature contributes to the model’s predictions.
    
    The method works by randomly shuffling the values of one feature at a time and observing how much the model’s average prediction probability changes. If shuffling a feature causes a large drop in performance, that feature is considered more important.
    
    A bar chart is then plotted to visualize the top 10 most influential features, showing how each one affects the loan approval probability. This provides interpretability, explainability and transparency by highlighting which factors the model relies on most in its decision-making.

    
"""

# --- permutation feature importance ---
def permutation_importance(model, feature_cols, loader, top_k=10):
    model.eval()
    with torch.no_grad():
        batch_x, _ = next(iter(loader))
        batch_x = batch_x.to(DEVICE)
        base = torch.sigmoid(model(batch_x)).mean().item()

    n = batch_x.size(0)
    imps = {}
    for i, fname in enumerate(feature_cols):
        with torch.no_grad():
            perm = torch.randperm(n, device=DEVICE)
            pert = batch_x.clone()
            pert[:, i] = pert[perm, i]
            imp = base - torch.sigmoid(model(pert)).mean().item()
            imps[fname] = imp

    ranked = sorted(imps.items(), key=lambda x: abs(x[1]), reverse=True)
    feats, vals = zip(*ranked[:top_k])
    plt.figure(figsize=(7,4.5)); plt.barh(feats, vals); plt.xlabel('Δ mean prob'); plt.title('Top Feature Importance')
    plt.tight_layout(); plt.show()
    return ranked

"""10) Execution

    This section is where we run all the functions defined in the earlier sections above.

    The best threshold is 0.45, which means that the classifier performs best when it labels an applicant as Approved if the predicted probability is greater than or equal to 0.45. Using this threshold, we obtained an F1 score of 0.9783, indicating excellent balance between precision and recall.
    
    At this threshold, the model achieved a loss of 0.0840, accuracy of 95.01%, and an AUC of 0.9920, showing that it can effectively distinguish between approved and rejected applicants. The high AUC value (close to 1) demonstrates outstanding classification capability, meaning the model can  separate positive (approved) and negative (rejected) cases effectively.

    The feature importance chart highlights that features such as loan amount, income, loan term, and luxury asset value have the strongest influence on the model’s decision, reflecting logical relationships between applicant finances and loan approval outcomes.

    The visualisations illustrate the model’s overall metrics and performance. They provide a clear overview of how well the model classifies applicants, evaluates trade-offs between precision and recall, and identifies the most influential features contributing to loan approval decisions. Together, these plots offer a comprehensive understanding of the model’s effectiveness and decision-making behaviour.
"""

# --- main run  ---

# 1) preprocess
X_train, y_train, X_val, y_val, X_test, y_test, scaler, encoders, feature_cols = preprocess_data(df)

# 2) loaders
train_loader, val_loader, test_loader = make_loaders(X_train, y_train, X_val, y_val, X_test, y_test, batch_size=64)

# 3) model & training objects
model = LoanApprovalModel(input_size=len(feature_cols)).to(DEVICE)
criterion, optimizer, scheduler = make_training_objects(model, y_train)

# 4) train
train_losses, val_losses, train_accs, val_accs, lrs = train_model(
    model, train_loader, val_loader, criterion, optimizer, scheduler,
    epochs=10, early_stop_patience=20, ckpt_path='best_loan_model.pth'
)

# 5) tune threshold on validation
best_thr, best_f1 = tune_threshold(model, val_loader)
print(f"Best threshold (val F1): {best_thr:.3f} | F1={best_f1:.4f}")

# 6) evaluate on test
acc, auc, probs, y_true = evaluate(model, test_loader, criterion, threshold=best_thr)

# 7) feature importance
ranked_imps = permutation_importance(model, feature_cols, test_loader, top_k=10)

"""11. Equalised Odds

    This section evaluates the model’s fairness by checking whether it performs consistently across different demographic or categorical groups. specifically education level, employment type, and number of dependents.

    The metric is calculated by measuring the absolute difference in True Positive Rates (TPR) between each legally permitted subgroup and the overall reference group. A smaller difference indicates that qualified individuals across demographic groups have equal chances of receiving positive outcomes (for example, loan approvals).

    For the education attribute, the model’s True Positive Rates (TPR) for graduates (0.9424) and non-graduates (0.9423) are almost identical, showing an extremely small TPR difference of 0.0001. This means the model treats both groups nearly equally.

    For employment type, the model demonstrates a slightly higher TPR for self-employed (Yes) applicants (0.9657) compared to non-self-employed (No) applicants (0.9179), reflecting a moderate disparity of about 4.8 percentage points. This gap may arise from differences in income stability or data representation across employment categories. Nonetheless, the FPR difference remains small (≈2.1%), indicating that the model does not significantly over-approve one group relative to the other.

    For the number of dependents, the model’s True Positive Rate (TPR) varies slightly across subgroups, ranging from 0.9206 (for applicants with no dependents) to 0.9692 (for those with two or three dependents). This results in a TPR difference of approximately 4.9 percentage points, indicating mild variation in how the model approves loans across these groups.


"""

def equalised_odds_by_group(y_true, y_pred, group_values, group_name="Group"):
    """
    Compute Equalised Odds metrics (TPR/FPR per group) and their differences.

    Parameters:
        y_true (array-like): True binary labels (0/1)
        y_pred (array-like): Predicted binary labels (0/1)
        group_values (array-like): Sensitive attribute values (e.g. education levels)
        group_name (str): Name of the group for reporting

    Returns:
        results_df (pd.DataFrame): TPR/FPR for each group
        eo_diff (dict): Differences in TPR/FPR across groups
    """
    df = pd.DataFrame({
        'y_true': y_true,
        'y_pred': y_pred,
        'group': group_values
    })

    results = []
    for g, sub in df.groupby('group'):
        tn, fp, fn, tp = confusion_matrix(sub['y_true'], sub['y_pred']).ravel()
        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # recall for positive class
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # false positive rate
        results.append({'Group': g, 'TPR': tpr, 'FPR': fpr})

    results_df = pd.DataFrame(results)
    tpr_diff = results_df['TPR'].max() - results_df['TPR'].min()
    fpr_diff = results_df['FPR'].max() - results_df['FPR'].min()

    print(f"\n=== Equalised Odds for {group_name} ===")
    print(results_df.to_string(index=False))
    print(f"\nTPR Difference: {tpr_diff:.4f}")
    print(f"FPR Difference: {fpr_diff:.4f}")

    eo_diff = {'TPR_diff': tpr_diff, 'FPR_diff': fpr_diff}
    return results_df, eo_diff

"""12) EOD Results"""

# true labels and predictions from your test set
y_pred = (probs >= best_thr).astype(int)

# subgroup columns (assuming from your original dataframe or label encoder)
education_groups = df.loc[y_test.index, 'education']
employment_groups = df.loc[y_test.index, 'self_employed']
dependents_groups = df.loc[y_test.index, 'no_of_dependents']

# compute equalised odds per attribute
eq_edu, edu_diff = equalised_odds_by_group(y_true, y_pred, education_groups, group_name="Education")
eq_emp, emp_diff = equalised_odds_by_group(y_true, y_pred, employment_groups, group_name="Employment Type")
eq_dep, dep_diff = equalised_odds_by_group(y_true, y_pred, dependents_groups, group_name="Number of Dependents")

"""13) SHAP Evaluation"""

"""13) SHAP Evaluation (deterministic + stable feature importance, emoji-free)"""

def _set_local_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

# --- Simple SHAP analysis for model interpretability (reproducible & stable) ---
def simple_shap_analysis(model, feature_cols, X_test, y_test, probs, threshold=0.5, seed=SEED):
    print("=== SHAP FEATURE IMPORTANCE ===")

    _set_local_seeds(seed)

    # Fixed sample and background (float32 arrays)
    X_sample = np.asarray(X_test[:100], dtype=np.float32)
    background = np.asarray(X_train[:50], dtype=np.float32)

    # Freeze a CPU copy of the model for deterministic inference
    model_cpu = deepcopy(model).to("cpu").eval()
    torch.set_num_threads(1)  # avoid nondeterministic parallel math

    def model_predict(x):
        with torch.no_grad():
            x_tensor = torch.tensor(x, dtype=torch.float32, device="cpu")
            out = torch.sigmoid(model_cpu(x_tensor)).cpu().numpy()
        return out

    # Seed just before explainer to stabilize any internal sampling
    _set_local_seeds(seed)

    # Explicit permutation explainer with independent masker (deterministic given seeds)
    masker = shap.maskers.Independent(background)
    explainer = shap.explainers.Permutation(model_predict, masker)

    # Explain the fixed sample
    _set_local_seeds(seed)
    shap_values = explainer(X_sample)

    # Global importance (mean |SHAP| per feature)
    mean_abs_shap = np.mean(np.abs(shap_values.values), axis=0)

    # Build a stable, deterministic ranking:
    #  - round to fixed decimals for identical prints
    #  - stable mergesort
    feature_importance = pd.DataFrame({
        "feature": feature_cols,
        "importance": mean_abs_shap
    })
    feature_importance["importance"] = feature_importance["importance"].round(6)
    feature_importance = feature_importance.sort_values(
        by=["importance", "feature"], ascending=[False, True], kind="mergesort"
    ).reset_index(drop=True)

    print("\nTOP 10 FEATURES BY IMPORTANCE:")
    print(feature_importance.head(10).to_string(index=False))

    return shap_values, feature_importance

def show_customer_decisions(feature_cols, X_test, y_test, probs, scaler, threshold=0.5, num_customers=10, seed=SEED):
    """
    Deterministic customer selection (seeded) and emoji-free printing.
    """
    print("\n" + "="*80)
    print("DETAILED LOAN DECISIONS ANALYSIS FOR TEST CUSTOMERS")
    print("="*80)

    y_pred = (probs >= threshold).astype(int)

    rng = np.random.default_rng(seed)
    k = min(num_customers, len(X_test))
    indices = rng.choice(len(X_test), k, replace=False)

    for i, idx in enumerate(indices):
        customer_features = X_test[idx]
        true_label = y_test.iloc[idx] if hasattr(y_test, "iloc") else y_test[idx]
        true_status = "Approved" if int(true_label) == 1 else "Rejected"
        pred_prob = float(probs[idx])
        pred_status = "APPROVED" if y_pred[idx] == 1 else "REJECTED"
        confidence = "HIGH" if abs(pred_prob - 0.5) > 0.3 else "MEDIUM"

        customer_original = scaler.inverse_transform(customer_features.reshape(1, -1))[0]
        feature_dict = dict(zip(feature_cols, customer_original))

        print(f"\nCUSTOMER {i+1} PROFILE")
        print("-" * 50)
        print("DECISION SUMMARY:")
        print(f"   • Final Decision: {pred_status}")
        print(f"   • Confidence Level: {confidence}")
        print(f"   • Approval Probability: {pred_prob:.1%}")
        print(f"   • Actual Outcome: {true_status}")
        print(f"   • Risk Level: {'LOW' if pred_status == 'APPROVED' else 'HIGH'}")

        print("\nCUSTOMER BACKGROUND:")
        print(f"   • Education Level: {get_education_level(feature_dict)}")
        print(f"   • Employment Type: {get_employment_type(feature_dict)}")
        print(f"   • Dependents: {int(feature_dict.get('no_of_dependents', 0))} people")
        print(f"   • Annual Income: ${feature_dict.get('income_annum', 0):,.0f}")

        total_assets = (
            feature_dict.get('residential_assets_value', 0)
            + feature_dict.get('commercial_assets_value', 0)
            + feature_dict.get('luxury_assets_value', 0)
            + feature_dict.get('bank_asset_value', 0)
        )

        print("\nFINANCIAL PROFILE:")
        print(f"   • Loan Amount Requested: ${feature_dict.get('loan_amount', 0):,.0f}")
        print(f"   • Loan Term: {int(feature_dict.get('loan_term', 0))} years")
        print(f"   • Credit Score (CIBIL): {int(feature_dict.get('cibil_score', 0))}")
        print(f"   • Total Assets: ${total_assets:,.0f}")

        income = max(feature_dict.get('income_annum', 1), 1)
        loan_amount = max(feature_dict.get('loan_amount', 1), 1)
        loan_term_years = max(feature_dict.get('loan_term', 1), 1)
        loan_term_months = int(loan_term_years * 12)

        debt_to_income = loan_amount / income

        annual_interest_rate = 0.10
        monthly_interest = annual_interest_rate / 12.0
        if loan_term_months > 0:
            monthly_payment = loan_amount * (
                monthly_interest * (1 + monthly_interest) ** loan_term_months
            ) / ((1 + monthly_interest) ** loan_term_months - 1)
        else:
            monthly_payment = 0.0

        monthly_income = income / 12.0
        payment_to_income = monthly_payment / monthly_income if monthly_income > 0 else 0.0

        print("\nFINANCIAL RATIOS:")
        print(f"   • Debt-to-Income Ratio: {debt_to_income:.2f} (loan amount / annual income)")
        print(f"   • Estimated Monthly Payment: ${monthly_payment:,.0f}")
        print(f"   • Payment-to-Income Ratio: {payment_to_income:.1%} of monthly income")
        print(f"   • Loan Term: {loan_term_years} years ({loan_term_months} months)")

        if pred_status == "REJECTED":
            print("\nKEY REJECTION FACTORS:")
            risky_factors = identify_risk_factors(feature_dict)
            for j, (factor, severity, details) in enumerate(risky_factors[:3]):
                print(f"   {j+1}. [{severity}] {factor}")
                print(f"      {details}")
            print("\nRECOMMENDATION:")
            print(f"   Consider improving: {get_improvement_suggestions(risky_factors)}")
        else:
            print("\nKEY APPROVAL STRENGTHS:")
            strong_factors = identify_strength_factors(feature_dict)
            for j, (factor, strength, details) in enumerate(strong_factors[:3]):
                print(f"   {j+1}. [{strength}] {factor}")
                print(f"      {details}")
            print("\nRECOMMENDATION:")
            print("   Strong candidate - meets all key approval criteria")

        print("-" * 50)

# Execute (deterministic)
print("Performing Detailed SHAP Analysis...")

shap_values, feature_importance = simple_shap_analysis(
    model, feature_cols, X_test, y_test, probs, best_thr, seed=SEED
)

show_customer_decisions(
    feature_cols, X_test, y_test, probs, scaler, best_thr, num_customers=8, seed=SEED
)

print("\nDetailed SHAP analysis complete.")